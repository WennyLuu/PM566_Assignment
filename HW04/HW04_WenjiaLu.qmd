---
title: "PM566 Assinment04"
author: "Wenjia Lu"
format:
  html:
    embed-resources: true
---

### Set packages ###

```{r}

library(parallel)
library(RSQLite)
library(DBI)

```

###  HPC  ###

## Q1.Make things faster

# Rewrite the following R functions to make them faster. It is OK (and recommended) to take a look at Stackoverflow and Google

```{r}
# Total row sums
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}

fun1alt <- function(mat) {
  rowSums(mat)
}

# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2alt <- function(mat) {
  t(apply(mat,1,cumsum))
}

```

# Using the dataset henerated below(dat), check that the output of both of your new functions matches the output of the original functions. Then use microbenchmark to check that your version is actually faster.

```{r}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
t1= microbenchmark::microbenchmark(fun1(dat), fun1alt(dat))
print(t1, unit = "relative", check = "equivalent")

# Test for the second
t2= microbenchmark::microbenchmark(fun2(dat), fun2alt(dat))
print(t2, unit = "relative", check = "equivalent")

```


## Q2.Make things run faster with parallel computing

# The following function allows simulating PI

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132

```

# In order to get accurate estimates, we can run this function multiple times, with the following code:

```{r}
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})

```

# Rewrite the previous code using parLapply() to make it run faster. Make sure you set the seed using clusterSetRNGStream():

```{r}
cl <- makePSOCKcluster(4L) 
clusterSetRNGStream(cl, 1234)
n=10000
clusterExport(cl, c("n", "sim_pi"))
system.time({
  ans <- unlist(parLapply(cl, 1:4000, sim_pi, n))
  print(mean(ans))
})

stopCluster(cl)

```


### SQL ###

# Setup a temporary database by running the following chunk
# When you write a new chunk, remember to replace the r with sql, connection=con.

```{r}
# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)

```

## Q3.How many many movies is there avaliable in each rating catagory? 

```{sql, connection=con}

SELECT rating,
  COUNT(*) AS "Count"
FROM film
GROUP BY rating

```

## Q4.What is the average replacement cost and rental rate for each rating category?

```{sql, connection=con}

SELECT rating, 
  AVG(replacement_cost) AS "Average Replacement Cost",
  AVG(rental_rate) AS "Average Rental Rate"
FROM film
GROUP BY rating

```

## Q5.Use table film_category together with film to find the how many films there are with each category ID.

```{sql, connection=con}

SELECT category_id,
  COUNT(*) as "Count"
FROM film AS a INNER JOIN film_category AS b
on a.film_id = b.film_id
GROUP BY category_id 

```

## Q6.Incorporate table category into the answer to the previous question to find the name of the most popular category.

```{sql, connection=con}

SELECT c.name, b.category_id,
  COUNT(*) AS "Count"
FROM ((film_category AS b
INNER JOIN film AS a ON a.film_id = b.film_id)
INNER JOIN category AS c ON b.category_id = c.category_id)
GROUP BY c.name
ORDER BY "Count" DESC

```
** Sports is the most popular category.

## Clean up

```{r}

dbDisconnect(con)

```
